{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import datasets, transforms, models # --> new\n",
    "from torchmetrics.functional import accuracy\n",
    "# from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch.utils.data import DataLoader, random_split \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ecf0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_imgnumpy(image: torch.Tensor, denormalize=False) -> np.ndarray:\n",
    "    assert image.dim() == 3, f\"expecting [3,256,256], the input size is {image.size()}\" \n",
    "    \n",
    "    imgnumpy = image.numpy().transpose(1,2,0)\n",
    "    if denormalize:\n",
    "        imgnumpy = imgnumpy*np.array((0.485, 0.456, 0.406)) + np.array((0.229, 0.224, 0.22))\n",
    "    \n",
    "    imgnumpy = imgnumpy.clip(0, 1)\n",
    "    return imgnumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1a837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_imgnumpy_simple(image):\n",
    "    imgnumpy = image\n",
    "    imgnumpy = imgnumpy.squeeze()\n",
    "    return imgnumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a918b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from cifar10_models.inception import inception_v3\n",
    "# from cifar10_models.googlenet import googlenet\n",
    "# from cifar10_models.mobilenetv2 import mobilenet_v2\n",
    "# from cifar10_models.resnet import resnet18\n",
    "# from cifar10_models.densenet import densenet121\n",
    "modelUsed = xrv.models.ResNet(weights=\"resnet50-res512-all\")\n",
    "modelUsed.eval()\n",
    "\n",
    "print(modelUsed)\n",
    "print(modelUsed.model.fc.out_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce8b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNormalize(torch.nn.Module):\n",
    "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
    "    This transform does not support PIL Image.\n",
    "    Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``\n",
    "    channels, this transform will normalize each channel of the input\n",
    "    ``torch.*Tensor`` i.e.,\n",
    "    ``output[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
    "    .. note::\n",
    "        This transform acts out of place, i.e., it does not mutate the input tensor.\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "        inplace(bool,optional): Bool to make this operation in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "        \"\"\"\n",
    "        return (2 * (img.astype(np.float32) / 255) - 1.) * 1024\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std})\"\n",
    "\n",
    "class ToNumpy(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, img):\n",
    "        return np.array(img)\n",
    "    \n",
    "class AddColorChannel(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Check that images are 2D arrays\n",
    "        if len(img.shape) > 2:\n",
    "            img = img[:, :, 0]\n",
    "        if len(img.shape) < 2:\n",
    "            print(\"error, dimension lower than 2 for image\")\n",
    "        return img[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f204b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_log = {}\n",
    "\n",
    "def fix_resolution(x, resolution: int, model: nn.Module):\n",
    "        \"\"\"Check resolution of input and resize to match requested.\"\"\"\n",
    "\n",
    "        # just skip it if upsample was removed somehow\n",
    "        if not hasattr(model, 'upsample') or (model.upsample == None):\n",
    "            return x\n",
    "\n",
    "        if (x.shape[2] != resolution) | (x.shape[3] != resolution):\n",
    "            if not hash(model) in warning_log:\n",
    "                print(\"Warning: Input size ({}x{}) is not the native resolution ({}x{}) for this model. A resize will be performed but this could impact performance.\".format(x.shape[2], x.shape[3], resolution, resolution))\n",
    "                warning_log[hash(model)] = True\n",
    "            return model.upsample(x)\n",
    "        return x\n",
    "\n",
    "def warn_normalization(x):\n",
    "    \"\"\"Check normalization of input and warn if possibly wrong. When \n",
    "    processing an image that may likely not have the correct \n",
    "    normalization we can issue a warning. But running min and max on \n",
    "    every image/batch is costly so we only do it on the first image/batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Only run this check on the first image so we don't hurt performance.\n",
    "    if not \"norm_check\" in warning_log:\n",
    "        x_min = x.min()\n",
    "        x_max = x.max()\n",
    "        if torch.logical_or(-255 < x_min, x_max < 255) or torch.logical_or(x_min < -1024, 1024 < x_max):\n",
    "            print(f'Warning: Input image does not appear to be normalized correctly. The input image has the range [{x_min:.2f},{x_max:.2f}] which doesn\\'t seem to be in the [-1024,1024] range. This warning may be wrong though. Only the first image is tested and we are only using a heuristic in an attempt to save a user from using the wrong normalization.')\n",
    "            warning_log[\"norm_correct\"] = False\n",
    "        else:\n",
    "            warning_log[\"norm_correct\"] = True\n",
    "              \n",
    "        warning_log[\"norm_check\"] = True\n",
    "    \n",
    "class FinetunedModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # load pretrained model\n",
    "        model = xrv.models.ResNet(weights=\"resnet50-res512-all\")\n",
    "        \n",
    "        self.model = model.model\n",
    "        \n",
    "        self.conv1 = model.model.conv1\n",
    "        self.bn1 = model.model.bn1\n",
    "        self.relu = model.model.relu\n",
    "        self.maxpool = model.model.maxpool\n",
    "\n",
    "        self.layer1 = model.model.layer1\n",
    "        self.layer2 = model.model.layer2\n",
    "        self.layer3 = model.model.layer3\n",
    "        self.layer4 = model.model.layer4\n",
    "\n",
    "        self.avgpool = model.model.avgpool\n",
    "        \n",
    "        self.fc = model.model.fc\n",
    "        \n",
    "#         freeze the feature learning\n",
    "        for param in self.conv1.parameters():\n",
    "              param.requires_grad = False\n",
    "        \n",
    "        for param in self.bn1.parameters():\n",
    "              param.requires_grad = False\n",
    "                \n",
    "        for param in self.relu.parameters():\n",
    "              param.requires_grad = False\n",
    "                \n",
    "        for param in self.maxpool.parameters():\n",
    "              param.requires_grad = False\n",
    "                \n",
    "        for param in self.layer1.parameters():\n",
    "              param.requires_grad = False\n",
    "        \n",
    "        for param in self.layer2.parameters():\n",
    "              param.requires_grad = False\n",
    "                \n",
    "        for param in self.layer3.parameters():\n",
    "              param.requires_grad = False\n",
    "                \n",
    "        for param in self.layer4.parameters():\n",
    "              param.requires_grad = False\n",
    "        \n",
    "        # change the number of output classes of the last layer\n",
    "        # this is useless line as it the number of output classes is already set to be 10\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=self.fc.in_features,\n",
    "            out_features=2)\n",
    "        \n",
    "        # follow https://pytorch.org/hub/pytorch_vision_alexnet/\n",
    "        tf_tonumpy = ToNumpy()\n",
    "        tf_custom_normalize = CustomNormalize()\n",
    "        tf_add_color_channel = AddColorChannel()\n",
    "        tf_totensor = transforms.ToTensor()\n",
    "        self.tf_compose = transforms.Compose([\n",
    "            tf_tonumpy,\n",
    "            tf_custom_normalize,\n",
    "            tf_add_color_channel,\n",
    "#             xrv.datasets.XRayCenterCrop(),\n",
    "            xrv.datasets.XRayResizer(512),\n",
    "#             tf_totensor\n",
    "        ])\n",
    "    \n",
    "    def features(self, x):\n",
    "        x = fix_resolution(x, 512, self)\n",
    "        warn_normalization(x)\n",
    "        \n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = fix_resolution(x, 512, self)\n",
    "        warn_normalization(x)\n",
    "        \n",
    "        out = self.model(x)\n",
    "        \n",
    "        if hasattr(self, 'apply_sigmoid') and self.apply_sigmoid:\n",
    "            out = torch.sigmoid(out)\n",
    "        \n",
    "        if hasattr(self,\"op_threshs\") and (self.op_threshs != None):\n",
    "            out = torch.sigmoid(out)\n",
    "            out = op_norm(out, self.op_threshs)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Copy paste from the previous article\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "        loss = F.cross_entropy(outputs,labels) # --> NEW. Using nn.CrossEntropyLoss\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # This is new, but the structure is the same as training_step\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = accuracy(preds, labels) # --> NEW\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # This is new, but the structure is the same as test_step\n",
    "        # but I replace val_loss --> test_loss etc\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = accuracy(preds, labels)\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # split, transform, secretly move to GPU (if needed) by PL (not by us)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            dataset_full = datasets.ImageFolder(root='./data/Batch 1/Train/', transform=self.tf_compose)\n",
    "            \n",
    "            # split\n",
    "            SIZE_TRAIN_DATA = int(len(dataset_full)*0.75)\n",
    "            SIZE_VAL_DATA = len(dataset_full)-SIZE_TRAIN_DATA\n",
    "            self.dataset_train, self.dataset_val = random_split(dataset_full, [SIZE_TRAIN_DATA,SIZE_VAL_DATA])\n",
    "            \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.dataset_test = datasets.ImageFolder(root='./data//Batch 1/Test/', transform=self.tf_compose)\n",
    "            \n",
    "#         import pdb; pdb.set_trace()\n",
    "            \n",
    "    def train_dataloader(self): \n",
    "        return DataLoader(self.dataset_train, batch_size=50, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=50, num_workers=0)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset_test, batch_size=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3580ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.seed_everything(88) # --> for consistency, change the number with your favorite number :D\n",
    "\n",
    "# model = FinetunedModel()\n",
    "\n",
    "# # most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# try:\n",
    "#     trainer = pl.Trainer(gpus=1,max_epochs=1,default_root_dir='./batch3_logs')\n",
    "# except Exception as e:\n",
    "#     # most likely due to GPU, so fallback to non GPU\n",
    "#     print(e)\n",
    "#     trainer = pl.Trainer(max_epochs=1,default_root_dir='./batch3_logs')\n",
    "\n",
    "# trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60616d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_classes = ['Clean','Dirty']\n",
    "\n",
    "# def imshow(imgnumpy: np.ndarray, label, denormalize=False):\n",
    "#     plt.imshow(tensor_to_imgnumpy_simple(imgnumpy))\n",
    "#     plt.title(dataset_classes[label])\n",
    "    \n",
    "# loader = DataLoader(model.dataset_test, batch_size=1, shuffle=True)\n",
    "\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# for idx,(img,label) in enumerate(loader):\n",
    "#     plt.subplot(4,10,idx+1)\n",
    "#     imshow(img[0],label,denormalize=True)\n",
    "    \n",
    "#     # inference\n",
    "#     try:\n",
    "#         pred = model.forward(img.cuda())\n",
    "#     except Exception as e:\n",
    "#         pred =  model.forward(img)\n",
    "#         print(e)\n",
    "\n",
    "#     title_dataset = dataset_classes[label]\n",
    "#     title_pred = dataset_classes[pred.argmax()]\n",
    "#     plt.title(f\"{title_dataset}({title_pred})\",color=(\"green\" if title_dataset==title_pred else \"red\"))\n",
    "    \n",
    "#     if idx == 40-1:\n",
    "#         break\n",
    "        \n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22abc233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b4ae9074d5523ac3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b4ae9074d5523ac3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir custom_logs/ --port=6013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3f2b50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(88)\n",
    "path = \"./custom_logs/lightning_logs/resnet-xrv-classifier-version3-50epochs-batch3/checkpoints/epoch=49-step=1350.ckpt\"\n",
    "model = FinetunedModel.load_from_checkpoint(checkpoint_path=path, strict=False)\n",
    "\n",
    "model.current_epoch\n",
    "\n",
    "\n",
    "# print(model.learning_rate)\n",
    "# prints the learning_rate you used in this checkpoint\n",
    "                                                                    \n",
    "# model.eval()\n",
    "# y_hat = model(x)\n",
    "\n",
    "# model = FinetunedModel()\n",
    "# trainer = pl.Trainer()\n",
    "\n",
    "# trainer.test(model)\n",
    "# checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "# print(checkpoint[\"state_dict\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./custom_logs/lightning_logs/version_2//checkpoints/epoch=0-step=11.ckpt\"\n",
    "model = FinetunedModel.load_from_checkpoint(checkpoint_path=path)\n",
    "\n",
    "model = FinetunedModel()\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "\n",
    "trainer.fit(model, ckpt_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894be6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
